{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BookGenomeAnalysis\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+\n",
      "|item_id| num|tag_id|\n",
      "+-------+----+------+\n",
      "|    115|  52|    13|\n",
      "|    115| 180|    25|\n",
      "|    115| 110|    38|\n",
      "|    115|  42|    47|\n",
      "|    115| 478|    52|\n",
      "|    115|  94|   104|\n",
      "|    115|  72|   129|\n",
      "|    115| 607|   139|\n",
      "|    115|1610|   141|\n",
      "|    115|2429|   142|\n",
      "|    115|3510|   151|\n",
      "|    115| 123|   161|\n",
      "|    115| 208|   212|\n",
      "|    115|  46|   214|\n",
      "|    115|  41|   225|\n",
      "|    115|  40|   247|\n",
      "|    115|2025|   259|\n",
      "|    115|  43|   275|\n",
      "|    115|  96|   326|\n",
      "|    115| 163|   381|\n",
      "|    115| 337|   383|\n",
      "|    115| 143|   395|\n",
      "|    115| 259|   435|\n",
      "|    115| 113|   436|\n",
      "|    115| 140|   481|\n",
      "|    115| 270|   547|\n",
      "|    115|  60|   571|\n",
      "|    115| 380|   579|\n",
      "|    115| 101|   657|\n",
      "|    115|  46|   659|\n",
      "|    115|2064|   672|\n",
      "|    115| 131|   725|\n",
      "|    387|  10|    23|\n",
      "|    387|   7|    47|\n",
      "|    387|  18|    75|\n",
      "|    387|  84|    93|\n",
      "|    387|   4|   114|\n",
      "|    387|   5|   166|\n",
      "|    387|  10|   186|\n",
      "|    387|   4|   223|\n",
      "|    387|   6|   230|\n",
      "|    387|  15|   247|\n",
      "|    387|  32|   259|\n",
      "|    387|   8|   276|\n",
      "|    387|   7|   277|\n",
      "|    387|  11|   342|\n",
      "|    387|   7|   377|\n",
      "|    387|   9|   392|\n",
      "|    387|  19|   402|\n",
      "|    387|  71|   426|\n",
      "+-------+----+------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tag_df = spark.read.json(\"book-genome\\\\book_dataset\\\\raw\\\\tag_count.json\")\n",
    "tag_df.show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+----+\n",
      "|item_id| num|tag_id|rank|\n",
      "+-------+----+------+----+\n",
      "|    115|3510|   151|   1|\n",
      "|    115|2429|   142|   2|\n",
      "|    115|2064|   672|   3|\n",
      "|    115|2025|   259|   4|\n",
      "|    115|1610|   141|   5|\n",
      "|    387| 529|   478|   1|\n",
      "|    387| 146|   534|   2|\n",
      "|    387|  84|    93|   3|\n",
      "|    387|  71|   426|   4|\n",
      "|    387|  67|   589|   5|\n",
      "|    423|7034|   580|   1|\n",
      "|    423|1060|   259|   2|\n",
      "|    423| 330|   706|   3|\n",
      "|    423| 222|   151|   4|\n",
      "|    423| 202|   438|   5|\n",
      "|    434| 797|   462|   1|\n",
      "|    434| 671|   179|   2|\n",
      "|    434| 629|   259|   3|\n",
      "|    434| 299|   477|   4|\n",
      "|    434| 235|   669|   5|\n",
      "|    466| 862|   512|   1|\n",
      "|    466| 289|   259|   2|\n",
      "|    466| 288|   602|   3|\n",
      "|    466| 257|   249|   4|\n",
      "|    466| 138|   342|   5|\n",
      "|    505|1663|   249|   1|\n",
      "|    505| 772|   672|   2|\n",
      "|    505| 267|   259|   3|\n",
      "|    505| 241|   564|   4|\n",
      "|    505| 215|   326|   5|\n",
      "|    574|1413|   478|   1|\n",
      "|    574| 824|   238|   2|\n",
      "|    574| 153|   342|   3|\n",
      "|    574|  99|   602|   4|\n",
      "|    574|  80|   426|   5|\n",
      "|    696|2439|   580|   1|\n",
      "|    696| 826|   671|   2|\n",
      "|    696| 697|   259|   3|\n",
      "|    696| 390|   249|   4|\n",
      "|    696| 297|   342|   5|\n",
      "|    731| 826|   342|   1|\n",
      "|    731| 613|   478|   2|\n",
      "|    731| 354|   238|   3|\n",
      "|    731| 338|   602|   4|\n",
      "|    731| 288|   426|   5|\n",
      "|    742| 692|   249|   1|\n",
      "|    742| 549|   672|   2|\n",
      "|    742| 508|   142|   3|\n",
      "|    742| 492|   259|   4|\n",
      "|    742| 401|   141|   5|\n",
      "+-------+----+------+----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We find the most popular tag for each book.\n",
    "from pyspark.sql.functions import col, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "window_spec = Window.partitionBy(\"item_id\").orderBy(col(\"num\").desc())\n",
    "\n",
    "top_tags_df = tag_df.withColumn(\"rank\", row_number().over(window_spec)).filter(col(\"rank\") <= 5)\n",
    "top_tags_df.show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|tag_id|sum(num)|\n",
      "+------+--------+\n",
      "|   672| 5627942|\n",
      "|   249| 5355792|\n",
      "|   259| 4929087|\n",
      "|   151| 2631087|\n",
      "|   580| 2158948|\n",
      "|   564| 1996633|\n",
      "|   207| 1324692|\n",
      "|   478| 1266736|\n",
      "|   462| 1223647|\n",
      "|   166|  885600|\n",
      "|   495|  779765|\n",
      "|   142|  616277|\n",
      "|   686|  541936|\n",
      "|   481|  514698|\n",
      "|   304|  513694|\n",
      "|   141|  512189|\n",
      "|    23|  497055|\n",
      "|   694|  471663|\n",
      "|   669|  448372|\n",
      "|    25|  434346|\n",
      "|   335|  427146|\n",
      "|   410|  379831|\n",
      "|   326|  357972|\n",
      "|   136|  329706|\n",
      "|   395|  301460|\n",
      "|   342|  298289|\n",
      "|   426|  290027|\n",
      "|   465|  280647|\n",
      "|   659|  268079|\n",
      "|   327|  259846|\n",
      "|   179|  242524|\n",
      "|   159|  235094|\n",
      "|   643|  232561|\n",
      "|    38|  230741|\n",
      "|   139|  228207|\n",
      "|    13|  225679|\n",
      "|    93|  207374|\n",
      "|   547|  200120|\n",
      "|   650|  168959|\n",
      "|   435|  158783|\n",
      "|   579|  158186|\n",
      "|   230|  158090|\n",
      "|   293|  156553|\n",
      "|   214|  146530|\n",
      "|   602|  137988|\n",
      "|   629|  135673|\n",
      "|   236|  121605|\n",
      "|   383|  119780|\n",
      "|   464|  118175|\n",
      "|   397|  115633|\n",
      "+------+--------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We find the tags most frequently applied across all books\n",
    "tag_counts = tag_df.groupBy(\"tag_id\").sum(\"num\").orderBy(col(\"sum(num)\").desc())\n",
    "tag_counts.show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "| item_id|total_tag_votes|\n",
      "+--------+---------------+\n",
      "| 4640799|         973596|\n",
      "| 2792775|         764914|\n",
      "| 8812783|         493724|\n",
      "| 6231171|         400278|\n",
      "| 2402163|         396207|\n",
      "|13155899|         368561|\n",
      "| 3275794|         327339|\n",
      "|15524549|         299644|\n",
      "| 2963218|         284836|\n",
      "|41335427|         277272|\n",
      "| 6171458|         271994|\n",
      "|16827462|         260108|\n",
      "| 3060926|         248843|\n",
      "| 1708725|         224763|\n",
      "|15524542|         222136|\n",
      "|14863741|         219249|\n",
      "|15545385|         195102|\n",
      "|  878368|         182824|\n",
      "| 3036731|         181205|\n",
      "| 1970226|         180983|\n",
      "|  153313|         179926|\n",
      "| 6366642|         164380|\n",
      "| 2422333|         162791|\n",
      "| 2982101|         161923|\n",
      "|  245494|         153033|\n",
      "|14345371|         152760|\n",
      "| 1272463|         150123|\n",
      "|41107568|         148520|\n",
      "| 3212258|         145218|\n",
      "|13306276|         138813|\n",
      "| 2207778|         137801|\n",
      "|13355552|         131896|\n",
      "| 2267189|         123783|\n",
      "|14245059|         123017|\n",
      "| 1565818|         121864|\n",
      "| 3204877|         116697|\n",
      "| 2766512|         114538|\n",
      "|14302659|         111662|\n",
      "| 2236198|         109161|\n",
      "| 3078186|         104183|\n",
      "|21825181|         103484|\n",
      "|17225055|         103073|\n",
      "| 4422413|          98156|\n",
      "|11138426|          97676|\n",
      "| 2507928|          96522|\n",
      "|   46663|          96478|\n",
      "|  919292|          96383|\n",
      "|  948387|          95754|\n",
      "| 2153746|          93904|\n",
      "| 4717423|          92840|\n",
      "+--------+---------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We find out the most popular books base on their tags.\n",
    "tags_per_book = tag_df.groupBy(\"item_id\").sum(\"num\").withColumnRenamed(\"sum(num)\", \"total_tag_votes\")\n",
    "tags_per_book.orderBy(col(\"total_tag_votes\").desc()).show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "| item_id|unique_tags|\n",
      "+--------+-----------+\n",
      "|26129516|         47|\n",
      "|25370670|         46|\n",
      "|25209900|         46|\n",
      "|25589246|         46|\n",
      "|42804162|         46|\n",
      "| 3303888|         45|\n",
      "|24803357|         45|\n",
      "| 3389674|         44|\n",
      "|   47950|         43|\n",
      "|28166399|         43|\n",
      "|45363962|         43|\n",
      "|   69081|         43|\n",
      "|41106601|         43|\n",
      "| 1947012|         43|\n",
      "| 2000351|         42|\n",
      "|45620597|         42|\n",
      "|45900469|         42|\n",
      "|41941424|         42|\n",
      "|43165888|         42|\n",
      "|51383662|         42|\n",
      "|19694996|         42|\n",
      "|17441876|         42|\n",
      "|24070983|         42|\n",
      "|18166592|         42|\n",
      "|13344769|         42|\n",
      "| 1743336|         42|\n",
      "| 6127168|         41|\n",
      "|42421291|         41|\n",
      "|21987573|         41|\n",
      "|50652749|         41|\n",
      "| 1995335|         41|\n",
      "|26415493|         41|\n",
      "| 6568189|         41|\n",
      "|49343156|         41|\n",
      "|17912072|         41|\n",
      "|18285292|         41|\n",
      "| 1782551|         41|\n",
      "| 3271379|         40|\n",
      "|21768943|         40|\n",
      "|41912642|         40|\n",
      "|42397963|         40|\n",
      "|25364368|         40|\n",
      "|25463804|         40|\n",
      "|14826219|         40|\n",
      "|21544272|         40|\n",
      "| 9871439|         40|\n",
      "|42426961|         40|\n",
      "| 1145090|         40|\n",
      "|19212100|         40|\n",
      "| 3062141|         40|\n",
      "+--------+-----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now Count how many unique tags each book has\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "tag_diversity = tag_df.groupBy(\"item_id\").agg(countDistinct(\"tag_id\").alias(\"unique_tags\"))\n",
    "tag_diversity.orderBy(col(\"unique_tags\").desc()).show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "|id |tag         |\n",
      "+---+------------+\n",
      "|0  |18th century|\n",
      "|1  |1920s       |\n",
      "|2  |1930s       |\n",
      "|3  |1950s       |\n",
      "|4  |1960s       |\n",
      "+---+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags_df = spark.read.json(\"book-genome/book_dataset/raw/tags.json\")\n",
    "tags_df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----+------------------+\n",
      "|tag_id|item_id|num |tag               |\n",
      "+------+-------+----+------------------+\n",
      "|151   |115    |3510|classic           |\n",
      "|142   |115    |2429|childhood         |\n",
      "|672   |115    |2064|young adult       |\n",
      "|259   |115    |2025|fiction           |\n",
      "|141   |115    |1610|children's books  |\n",
      "|139   |115    |607 |children          |\n",
      "|52    |115    |478 |animals           |\n",
      "|579   |115    |380 |school            |\n",
      "|383   |115    |337 |kids              |\n",
      "|547   |115    |270 |realistic fiction |\n",
      "|435   |115    |259 |middle grade      |\n",
      "|212   |115    |208 |dogs              |\n",
      "|25    |115    |180 |adventure         |\n",
      "|381   |115    |163 |juvenile          |\n",
      "|395   |115    |143 |literature        |\n",
      "|481   |115    |140 |novel             |\n",
      "|725   |115    |131 |youth             |\n",
      "|161   |115    |123 |coming of age     |\n",
      "|436   |115    |113 |middle school     |\n",
      "|38    |115    |110 |all time favorites|\n",
      "+------+-------+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Rename `id` to `tag_id` in tags_df so we can join\n",
    "tags_df = tags_df.withColumnRenamed(\"id\", \"tag_id\")\n",
    "\n",
    "# Now join will work\n",
    "book_tags = tag_df.filter(col(\"item_id\").isin(115, 387)).join(tags_df, on=\"tag_id\")\n",
    "\n",
    "# Show results ordered by item_id and most used tags\n",
    "book_tags.orderBy(\"item_id\", col(\"num\").desc()).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-----+--------------------+-----+-----+--------------+\n",
      "|item_id|num|tag_id|total|normalized_num      |total|total|total_per_book|\n",
      "+-------+---+------+-----+--------------------+-----+-----+--------------+\n",
      "|63710  |5  |8     |1499 |0.00333555703802535 |1499 |1499 |1499          |\n",
      "|63710  |6  |23    |1499 |0.004002668445630421|1499 |1499 |1499          |\n",
      "|63710  |7  |47    |1499 |0.004669779853235491|1499 |1499 |1499          |\n",
      "|63710  |6  |65    |1499 |0.004002668445630421|1499 |1499 |1499          |\n",
      "|63710  |74 |75    |1499 |0.049366244162775186|1499 |1499 |1499          |\n",
      "|63710  |333|93    |1499 |0.22214809873248834 |1499 |1499 |1499          |\n",
      "|63710  |10 |94    |1499 |0.0066711140760507  |1499 |1499 |1499          |\n",
      "|63710  |7  |158   |1499 |0.004669779853235491|1499 |1499 |1499          |\n",
      "|63710  |13 |164   |1499 |0.00867244829886591 |1499 |1499 |1499          |\n",
      "|63710  |6  |166   |1499 |0.004002668445630421|1499 |1499 |1499          |\n",
      "|63710  |5  |230   |1499 |0.00333555703802535 |1499 |1499 |1499          |\n",
      "|63710  |18 |238   |1499 |0.01200800533689126 |1499 |1499 |1499          |\n",
      "|63710  |7  |277   |1499 |0.004669779853235491|1499 |1499 |1499          |\n",
      "|63710  |12 |285   |1499 |0.008005336891260841|1499 |1499 |1499          |\n",
      "|63710  |61 |342   |1499 |0.040693795863909275|1499 |1499 |1499          |\n",
      "|63710  |13 |343   |1499 |0.00867244829886591 |1499 |1499 |1499          |\n",
      "|63710  |5  |360   |1499 |0.00333555703802535 |1499 |1499 |1499          |\n",
      "|63710  |8  |396   |1499 |0.00533689126084056 |1499 |1499 |1499          |\n",
      "|63710  |201|426   |1499 |0.13408939292861907 |1499 |1499 |1499          |\n",
      "|63710  |661|478   |1499 |0.4409606404269513  |1499 |1499 |1499          |\n",
      "+-------+---+------+-----+--------------------+-----+-----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We then normalize tag counts to account for books with more exposure\n",
    "from pyspark.sql.functions import sum as _sum, col\n",
    "\n",
    "# Group by item_id and calculate total for each book\n",
    "total_per_book = tag_df.groupBy(\"item_id\").agg(_sum(\"num\").alias(\"total\"))\n",
    "\n",
    "# Rename the 'total' column from total_per_book to avoid ambiguity\n",
    "total_per_book = total_per_book.withColumnRenamed(\"total\", \"total_per_book\")\n",
    "\n",
    "# Join tag_df with the total_per_book to get the total counts per book\n",
    "tag_df = tag_df.join(total_per_book, on=\"item_id\", how=\"left\")\n",
    "\n",
    "# Add the normalized_num column using the 'num' from the original and 'total_per_book' from the total_per_book\n",
    "tag_df = tag_df.withColumn(\"normalized_num\", col(\"num\") / col(\"total_per_book\"))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "tag_df.show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mysparkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
