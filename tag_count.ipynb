{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BookGenomeAnalysis\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+\n",
      "|item_id| num|tag_id|\n",
      "+-------+----+------+\n",
      "|    115|  52|    13|\n",
      "|    115| 180|    25|\n",
      "|    115| 110|    38|\n",
      "|    115|  42|    47|\n",
      "|    115| 478|    52|\n",
      "|    115|  94|   104|\n",
      "|    115|  72|   129|\n",
      "|    115| 607|   139|\n",
      "|    115|1610|   141|\n",
      "|    115|2429|   142|\n",
      "|    115|3510|   151|\n",
      "|    115| 123|   161|\n",
      "|    115| 208|   212|\n",
      "|    115|  46|   214|\n",
      "|    115|  41|   225|\n",
      "|    115|  40|   247|\n",
      "|    115|2025|   259|\n",
      "|    115|  43|   275|\n",
      "|    115|  96|   326|\n",
      "|    115| 163|   381|\n",
      "|    115| 337|   383|\n",
      "|    115| 143|   395|\n",
      "|    115| 259|   435|\n",
      "|    115| 113|   436|\n",
      "|    115| 140|   481|\n",
      "|    115| 270|   547|\n",
      "|    115|  60|   571|\n",
      "|    115| 380|   579|\n",
      "|    115| 101|   657|\n",
      "|    115|  46|   659|\n",
      "|    115|2064|   672|\n",
      "|    115| 131|   725|\n",
      "|    387|  10|    23|\n",
      "|    387|   7|    47|\n",
      "|    387|  18|    75|\n",
      "|    387|  84|    93|\n",
      "|    387|   4|   114|\n",
      "|    387|   5|   166|\n",
      "|    387|  10|   186|\n",
      "|    387|   4|   223|\n",
      "|    387|   6|   230|\n",
      "|    387|  15|   247|\n",
      "|    387|  32|   259|\n",
      "|    387|   8|   276|\n",
      "|    387|   7|   277|\n",
      "|    387|  11|   342|\n",
      "|    387|   7|   377|\n",
      "|    387|   9|   392|\n",
      "|    387|  19|   402|\n",
      "|    387|  71|   426|\n",
      "+-------+----+------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tag_df = spark.read.json(\"book-genome\\\\book_dataset\\\\raw\\\\tag_count.json\")\n",
    "tag_df.show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+----+\n",
      "|item_id| num|tag_id|rank|\n",
      "+-------+----+------+----+\n",
      "|    115|3510|   151|   1|\n",
      "|    115|2429|   142|   2|\n",
      "|    115|2064|   672|   3|\n",
      "|    115|2025|   259|   4|\n",
      "|    115|1610|   141|   5|\n",
      "|    387| 529|   478|   1|\n",
      "|    387| 146|   534|   2|\n",
      "|    387|  84|    93|   3|\n",
      "|    387|  71|   426|   4|\n",
      "|    387|  67|   589|   5|\n",
      "|    423|7034|   580|   1|\n",
      "|    423|1060|   259|   2|\n",
      "|    423| 330|   706|   3|\n",
      "|    423| 222|   151|   4|\n",
      "|    423| 202|   438|   5|\n",
      "|    434| 797|   462|   1|\n",
      "|    434| 671|   179|   2|\n",
      "|    434| 629|   259|   3|\n",
      "|    434| 299|   477|   4|\n",
      "|    434| 235|   669|   5|\n",
      "|    466| 862|   512|   1|\n",
      "|    466| 289|   259|   2|\n",
      "|    466| 288|   602|   3|\n",
      "|    466| 257|   249|   4|\n",
      "|    466| 138|   342|   5|\n",
      "|    505|1663|   249|   1|\n",
      "|    505| 772|   672|   2|\n",
      "|    505| 267|   259|   3|\n",
      "|    505| 241|   564|   4|\n",
      "|    505| 215|   326|   5|\n",
      "|    574|1413|   478|   1|\n",
      "|    574| 824|   238|   2|\n",
      "|    574| 153|   342|   3|\n",
      "|    574|  99|   602|   4|\n",
      "|    574|  80|   426|   5|\n",
      "|    696|2439|   580|   1|\n",
      "|    696| 826|   671|   2|\n",
      "|    696| 697|   259|   3|\n",
      "|    696| 390|   249|   4|\n",
      "|    696| 297|   342|   5|\n",
      "|    731| 826|   342|   1|\n",
      "|    731| 613|   478|   2|\n",
      "|    731| 354|   238|   3|\n",
      "|    731| 338|   602|   4|\n",
      "|    731| 288|   426|   5|\n",
      "|    742| 692|   249|   1|\n",
      "|    742| 549|   672|   2|\n",
      "|    742| 508|   142|   3|\n",
      "|    742| 492|   259|   4|\n",
      "|    742| 401|   141|   5|\n",
      "+-------+----+------+----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We find the most popular tag for each book.\n",
    "from pyspark.sql.functions import col, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "window_spec = Window.partitionBy(\"item_id\").orderBy(col(\"num\").desc())\n",
    "\n",
    "top_tags_df = tag_df.withColumn(\"rank\", row_number().over(window_spec)).filter(col(\"rank\") <= 5)\n",
    "top_tags_df.show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|tag_id|sum(num)|\n",
      "+------+--------+\n",
      "|   672| 5627942|\n",
      "|   249| 5355792|\n",
      "|   259| 4929087|\n",
      "|   151| 2631087|\n",
      "|   580| 2158948|\n",
      "|   564| 1996633|\n",
      "|   207| 1324692|\n",
      "|   478| 1266736|\n",
      "|   462| 1223647|\n",
      "|   166|  885600|\n",
      "|   495|  779765|\n",
      "|   142|  616277|\n",
      "|   686|  541936|\n",
      "|   481|  514698|\n",
      "|   304|  513694|\n",
      "|   141|  512189|\n",
      "|    23|  497055|\n",
      "|   694|  471663|\n",
      "|   669|  448372|\n",
      "|    25|  434346|\n",
      "|   335|  427146|\n",
      "|   410|  379831|\n",
      "|   326|  357972|\n",
      "|   136|  329706|\n",
      "|   395|  301460|\n",
      "|   342|  298289|\n",
      "|   426|  290027|\n",
      "|   465|  280647|\n",
      "|   659|  268079|\n",
      "|   327|  259846|\n",
      "|   179|  242524|\n",
      "|   159|  235094|\n",
      "|   643|  232561|\n",
      "|    38|  230741|\n",
      "|   139|  228207|\n",
      "|    13|  225679|\n",
      "|    93|  207374|\n",
      "|   547|  200120|\n",
      "|   650|  168959|\n",
      "|   435|  158783|\n",
      "|   579|  158186|\n",
      "|   230|  158090|\n",
      "|   293|  156553|\n",
      "|   214|  146530|\n",
      "|   602|  137988|\n",
      "|   629|  135673|\n",
      "|   236|  121605|\n",
      "|   383|  119780|\n",
      "|   464|  118175|\n",
      "|   397|  115633|\n",
      "+------+--------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We find the tags most frequently applied across all books\n",
    "tag_counts = tag_df.groupBy(\"tag_id\").sum(\"num\").orderBy(col(\"sum(num)\").desc())\n",
    "tag_counts.show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "| item_id|total_tag_votes|\n",
      "+--------+---------------+\n",
      "| 4640799|         973596|\n",
      "| 2792775|         764914|\n",
      "| 8812783|         493724|\n",
      "| 6231171|         400278|\n",
      "| 2402163|         396207|\n",
      "|13155899|         368561|\n",
      "| 3275794|         327339|\n",
      "|15524549|         299644|\n",
      "| 2963218|         284836|\n",
      "|41335427|         277272|\n",
      "| 6171458|         271994|\n",
      "|16827462|         260108|\n",
      "| 3060926|         248843|\n",
      "| 1708725|         224763|\n",
      "|15524542|         222136|\n",
      "|14863741|         219249|\n",
      "|15545385|         195102|\n",
      "|  878368|         182824|\n",
      "| 3036731|         181205|\n",
      "| 1970226|         180983|\n",
      "|  153313|         179926|\n",
      "| 6366642|         164380|\n",
      "| 2422333|         162791|\n",
      "| 2982101|         161923|\n",
      "|  245494|         153033|\n",
      "|14345371|         152760|\n",
      "| 1272463|         150123|\n",
      "|41107568|         148520|\n",
      "| 3212258|         145218|\n",
      "|13306276|         138813|\n",
      "| 2207778|         137801|\n",
      "|13355552|         131896|\n",
      "| 2267189|         123783|\n",
      "|14245059|         123017|\n",
      "| 1565818|         121864|\n",
      "| 3204877|         116697|\n",
      "| 2766512|         114538|\n",
      "|14302659|         111662|\n",
      "| 2236198|         109161|\n",
      "| 3078186|         104183|\n",
      "|21825181|         103484|\n",
      "|17225055|         103073|\n",
      "| 4422413|          98156|\n",
      "|11138426|          97676|\n",
      "| 2507928|          96522|\n",
      "|   46663|          96478|\n",
      "|  919292|          96383|\n",
      "|  948387|          95754|\n",
      "| 2153746|          93904|\n",
      "| 4717423|          92840|\n",
      "+--------+---------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We find out the most popular books base on their tags.\n",
    "tags_per_book = tag_df.groupBy(\"item_id\").sum(\"num\").withColumnRenamed(\"sum(num)\", \"total_tag_votes\")\n",
    "tags_per_book.orderBy(col(\"total_tag_votes\").desc()).show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "| item_id|unique_tags|\n",
      "+--------+-----------+\n",
      "|26129516|         47|\n",
      "|25370670|         46|\n",
      "|25209900|         46|\n",
      "|25589246|         46|\n",
      "|42804162|         46|\n",
      "| 3303888|         45|\n",
      "|24803357|         45|\n",
      "| 3389674|         44|\n",
      "|   47950|         43|\n",
      "|28166399|         43|\n",
      "|45363962|         43|\n",
      "|   69081|         43|\n",
      "|41106601|         43|\n",
      "| 1947012|         43|\n",
      "| 2000351|         42|\n",
      "|45620597|         42|\n",
      "|45900469|         42|\n",
      "|41941424|         42|\n",
      "|43165888|         42|\n",
      "|51383662|         42|\n",
      "|19694996|         42|\n",
      "|17441876|         42|\n",
      "|24070983|         42|\n",
      "|18166592|         42|\n",
      "|13344769|         42|\n",
      "| 1743336|         42|\n",
      "| 6127168|         41|\n",
      "|42421291|         41|\n",
      "|21987573|         41|\n",
      "|50652749|         41|\n",
      "| 1995335|         41|\n",
      "|26415493|         41|\n",
      "| 6568189|         41|\n",
      "|49343156|         41|\n",
      "|17912072|         41|\n",
      "|18285292|         41|\n",
      "| 1782551|         41|\n",
      "| 3271379|         40|\n",
      "|21768943|         40|\n",
      "|41912642|         40|\n",
      "|42397963|         40|\n",
      "|25364368|         40|\n",
      "|25463804|         40|\n",
      "|14826219|         40|\n",
      "|21544272|         40|\n",
      "| 9871439|         40|\n",
      "|42426961|         40|\n",
      "| 1145090|         40|\n",
      "|19212100|         40|\n",
      "| 3062141|         40|\n",
      "+--------+-----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now Count how many unique tags each book has\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "tag_diversity = tag_df.groupBy(\"item_id\").agg(countDistinct(\"tag_id\").alias(\"unique_tags\"))\n",
    "tag_diversity.orderBy(col(\"unique_tags\").desc()).show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "|id |tag         |\n",
      "+---+------------+\n",
      "|0  |18th century|\n",
      "|1  |1920s       |\n",
      "|2  |1930s       |\n",
      "|3  |1950s       |\n",
      "|4  |1960s       |\n",
      "+---+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags_df = spark.read.json(\"book-genome/book_dataset/raw/tags.json\")\n",
    "tags_df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `tag_id` cannot be resolved on the right side of the join. The right-side columns: [`id`, `tag`].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m book_tags = \u001b[43mtag_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mitem_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m115\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m387\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtags_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtag_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m book_tags.orderBy(\u001b[33m\"\u001b[39m\u001b[33mitem_id\u001b[39m\u001b[33m\"\u001b[39m, col(\u001b[33m\"\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m\"\u001b[39m).desc()).show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheoc\\anaconda3\\envs\\mysparkenv\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:2493\u001b[39m, in \u001b[36mDataFrame.join\u001b[39m\u001b[34m(self, other, on, how)\u001b[39m\n\u001b[32m   2491\u001b[39m         on = \u001b[38;5;28mself\u001b[39m._jseq([])\n\u001b[32m   2492\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(how, \u001b[38;5;28mstr\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mhow should be a string\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2493\u001b[39m     jdf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m.sparkSession)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheoc\\anaconda3\\envs\\mysparkenv\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheoc\\anaconda3\\envs\\mysparkenv\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    181\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `tag_id` cannot be resolved on the right side of the join. The right-side columns: [`id`, `tag`]."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mysparkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
